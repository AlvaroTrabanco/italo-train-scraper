name: Build & Publish Italo GTFS + Stop Report

on:
  workflow_dispatch:
  schedule:
    - cron: "12 */1 * * *"  # every 1 hours at :12 UTC
  push:
    branches: [ "main" ]
    paths:
      - "coordinates.csv"
      - "scraper/**"
      - ".github/workflows/publish_gtfs.yml"
      - "scraper/trains.txt"
      - "index.html"

permissions:
  contents: write
  issues: write

concurrency:
  group: italo-gtfs-publish
  cancel-in-progress: true

jobs:
  build_publish:
    runs-on: ubuntu-latest
    env:
      SKIP_RUN: "0"
    steps:
      # Main branch checkout (code)
      - name: Checkout (main)
        uses: actions/checkout@v4

      # gh-pages checkout (persisted state + published site)
      - name: Checkout (gh-pages)
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      - name: Compute vars
        id: vars
        run: |
          # Service date is always "tomorrow"
          SERVICE_DATE="$(date -u -d 'tomorrow' +%Y%m%d)"
          echo "SERVICE_DATE=$SERVICE_DATE" >> $GITHUB_OUTPUT

          # Collection window = 8 days
          echo "WINDOW_HOURS=192" >> $GITHUB_OUTPUT

          # Export for later steps (github-script reads env, not outputs)
          echo "SERVICE_DATE=$SERVICE_DATE" >> $GITHUB_ENV

      - name: Restore persisted state (inventory + normalized_latest)
        run: |
          mkdir -p tmp_prev normalized_latest

          # Restore inventory if present
          if [ -f gh-pages/reports/stop_inventory.json ]; then
            cp gh-pages/reports/stop_inventory.json tmp_prev/stop_inventory.json
            echo "Restored stop_inventory.json"
          else
            echo "No previous stop_inventory.json found"
          fi

          # Restore cumulative normalized_latest if present
          if [ -d gh-pages/state/normalized_latest ]; then
            cp -R gh-pages/state/normalized_latest/. normalized_latest/
            echo "Restored normalized_latest ($(ls -1 normalized_latest | wc -l) files)"
          else
            echo "No previous normalized_latest found"
          fi

      - name: Check 8-day window (auto-stop)
        run: |
          mkdir -p public/state

          NOW_EPOCH=$(date -u +%s)

          if [ -f gh-pages/state/collection_started_epoch.txt ]; then
            START_EPOCH=$(cat gh-pages/state/collection_started_epoch.txt | tr -d '\n\r')
            echo "Collection started epoch: $START_EPOCH"
          else
            START_EPOCH=$NOW_EPOCH
            echo "Collection started epoch (new): $START_EPOCH"
          fi

          # Persist the start epoch every run
          echo "$START_EPOCH" > public/state/collection_started_epoch.txt

          ELAPSED=$((NOW_EPOCH - START_EPOCH))
          LIMIT=$((8 * 24 * 3600))

          if [ "$ELAPSED" -ge "$LIMIT" ]; then
            echo "8-day collection window reached. Skipping scrape/normalize/build."
            STOPPED_UTC=$(date -u +%Y%m%dT%H%M%SZ)
            echo "{ \"status\": \"stopped\", \"collection_started_epoch\": $START_EPOCH, \"stopped_utc\": \"$STOPPED_UTC\" }" > public/state/collection_status.json
            echo "SKIP_RUN=1" >> $GITHUB_ENV
          else
            NOW_UTC=$(date -u +%Y%m%dT%H%M%SZ)
            echo "{ \"status\": \"running\", \"collection_started_epoch\": $START_EPOCH, \"now_utc\": \"$NOW_UTC\", \"elapsed_seconds\": $ELAPSED, \"limit_seconds\": $LIMIT }" > public/state/collection_status.json
            echo "SKIP_RUN=0" >> $GITHUB_ENV
          fi

      - name: Scrape (from trains.txt)
        if: env.SKIP_RUN != '1'
        run: |
          mkdir -p out

          python scraper/italo_scrape.py \
            --trains-file scraper/trains.txt \
            --outdir out \
            --slice-size 999999 \
            --slice-index 0 \
            --skip-empty

          RUN_UTC=$(find out -maxdepth 1 -type d -name "20*T*Z" -printf "%f\n" | sort | tail -n 1)
          if [ -z "$RUN_UTC" ]; then
            echo "Could not detect RUN_UTC folder under out/"
            ls -la out || true
            exit 1
          fi

          echo "RUN_UTC=$RUN_UTC" >> $GITHUB_ENV
          echo "Scrape run folder: out/$RUN_UTC"

      - name: Normalize + merge into cumulative normalized_latest
        if: env.SKIP_RUN != '1'
        run: |
          OUTDIR="out/$RUN_UTC"
          NORMDIR="normalized/$RUN_UTC"
          mkdir -p "$NORMDIR"
          mkdir -p normalized_latest

          python scraper/normalize_italo.py --input-dir "$OUTDIR" --output-dir "$NORMDIR"

          # Merge this run into cumulative normalized_latest (overwrite per train)
          cp -f "$NORMDIR"/*.normalized.json normalized_latest/ 2>/dev/null || true

          echo "normalized_latest now has $(ls -1 normalized_latest | wc -l) files"

      - name: Build GTFS (stable + dated) from cumulative normalized_latest
        if: env.SKIP_RUN != '1'
        run: |
          WINDOW_HOURS="${{ steps.vars.outputs.WINDOW_HOURS }}"
          NORMDIR="normalized_latest"

          mkdir -p gtfs public/gtfs public/reports
          mkdir -p public/state/normalized_latest
          touch public/.nojekyll

          python scraper/build_gtfs.py \
            --normalized-dir "$NORMDIR" \
            --service-date "$SERVICE_DATE" \
            --out-zip "gtfs/italo_$SERVICE_DATE.zip"

          # Stable + dated copies to Pages
          cp "gtfs/italo_$SERVICE_DATE.zip" "public/gtfs/italo_latest.zip"
          cp "gtfs/italo_$SERVICE_DATE.zip" "public/gtfs/italo_$SERVICE_DATE.zip"

          # Persist cumulative normalized_latest to Pages state
          cp -f normalized_latest/*.normalized.json public/state/normalized_latest/ 2>/dev/null || true

          NORM_COUNT=$(ls -1 normalized_latest | wc -l)
          TRIPS_COUNT=$(python3 -c 'import os,zipfile; sd=os.environ["SERVICE_DATE"]; zp=f"gtfs/italo_{sd}.zip"; z=zipfile.ZipFile(zp); lines=z.read("trips.txt").decode("utf-8","replace").splitlines(); print(max(0,len(lines)-1))')

          cat > public/gtfs/latest.json <<EOF
          {
            "run_utc": "$RUN_UTC",
            "service_date": "$SERVICE_DATE",
            "window_hours": $WINDOW_HOURS,
            "latest_zip": "italo_latest.zip",
            "dated_zip": "italo_$SERVICE_DATE.zip",
            "normalized_latest_files": $NORM_COUNT,
            "gtfs_trips": $TRIPS_COUNT
          }
          EOF

          if [ -f public/index.html ]; then
            echo "index.html already in public/"
          elif [ -f index.html ]; then
            cp index.html public/index.html
          else
            echo "No index.html found (expected public/index.html in repo)."
          fi

      - name: Expected routes vs GTFS (missing routes report)
        if: env.SKIP_RUN != '1'
        env:
          SERVICE_DATE: ${{ steps.vars.outputs.SERVICE_DATE }}
        run: |
          SERVICE_DATE="${{ steps.vars.outputs.SERVICE_DATE }}"

          python3 scraper/report_missing_routes.py \
            --expected-csv "expected_routes_mapped.csv" \
            --gtfs-zip "gtfs/italo_${SERVICE_DATE}.zip" \
            --out-dir "public/reports" \
            --out-prefix "missing_routes"

      - name: Stop coordinates report (cumulative)
        if: env.SKIP_RUN != '1'
        run: |
          INV_IN="tmp_prev/stop_inventory.json"
          python scraper/report_stops.py \
            --normalized-dir "normalized_latest" \
            --coordinates "coordinates.csv" \
            --out-dir "public/reports" \
            --run-utc "$RUN_UTC" \
            $( [ -f "$INV_IN" ] && echo "--inventory-in $INV_IN" ) \
            --inventory-out "public/reports/stop_inventory.json" \
            --window-hours "${{ steps.vars.outputs.WINDOW_HOURS }}"

      - name: Alert if missing coordinates (create/update issue)
        if: env.SKIP_RUN != '1'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require("fs");

            const path = "public/reports/stops_report_latest.csv";
            if (!fs.existsSync(path)) {
              core.setFailed(`Missing report file: ${path}`);
              return;
            }

            const csv = fs.readFileSync(path, "utf8").trim().split(/\r?\n/);
            if (csv.length <= 1) {
              console.log("Report is empty (no rows).");
              return;
            }

            const rows = csv.slice(1).map(line => line.split(","));
            const missing = rows.filter(r => (r[1] || "").trim() === "MISSING_COORDINATES");
            const newNotIn = rows.filter(r => (r[1] || "").trim() === "NEW_NOT_IN_COORDINATES");

            const missingCount = missing.length;
            const newCount = newNotIn.length;

            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const title = "Italo GTFS: Missing stop coordinates";

            const runUtc = process.env.RUN_UTC || "(unknown)";
            const serviceDate = process.env.SERVICE_DATE || "(unknown)";

            // Find existing open issue with same title
            const { data: issues } = await github.rest.issues.listForRepo({
              owner, repo, state: "open", per_page: 50,
            });
            const existing = issues.find(i => i.title === title);

            if (missingCount === 0 && newCount === 0) {
              console.log("No missing/new stops. No alert needed.");

              if (existing) {
                await github.rest.issues.createComment({
                  owner, repo, issue_number: existing.number,
                  body: `âœ… All good now.\n\nRun: \`${runUtc}\`\nService date: \`${serviceDate}\``,
                });
                await github.rest.issues.update({
                  owner, repo, issue_number: existing.number,
                  state: "closed",
                });
              }
              return;
            }

            function topList(items, n=50) {
              return items.slice(0, n).map(r => `- ${r[0]}`).join("\n");
            }

            const body =
              `ðŸš¨ Some stops are missing coordinates.\n\n` +
              `Run: \`${runUtc}\`\n` +
              `Service date: \`${serviceDate}\`\n\n` +
              `Counts:\n` +
              `- MISSING_COORDINATES: **${missingCount}**\n` +
              `- NEW_NOT_IN_COORDINATES: **${newCount}**\n\n` +
              `Report (GitHub Pages):\n` +
              `- reports/stops_report_latest.csv\n` +
              `- reports/stops_report_latest.md\n\n` +
              `Top MISSING_COORDINATES:\n${topList(missing)}\n\n` +
              `Top NEW_NOT_IN_COORDINATES:\n${topList(newNotIn)}\n`;

            if (existing) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: existing.number,
                body,
              });
              console.log(`Updated existing issue #${existing.number}`);
            } else {
              const created = await github.rest.issues.create({
                owner, repo, title, body,
                labels: ["alert"],
              });
              console.log(`Created issue #${created.data.number}`);
            }
      - name: Create reports index
        run: |
          cat > public/reports/index.html <<EOF
          <h1>Reports</h1>
          <ul>
            <li><a href="missing_routes_latest.md">Missing Routes (MD)</a></li>
            <li><a href="missing_routes_latest.csv">Missing Routes (CSV)</a></li>
            <li><a href="stops_report_latest.md">Stops Report (MD)</a></li>
            <li><a href="stops_report_latest.csv">Stops Report (CSV)</a></li>
          </ul>
          EOF

      - name: Create site index (root)
        run: |
          mkdir -p public
          cat > public/index.html <<'EOF'
          <!doctype html>
          <html lang="en">
          <head>
            <meta charset="utf-8" />
            <meta name="viewport" content="width=device-width,initial-scale=1" />
            <title>Italo GTFS Export</title>
            <style>
              body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; line-height: 1.5; margin: 2rem; max-width: 900px; }
              .muted { color: #666; }
              .card { border: 1px solid #ddd; border-radius: 10px; padding: 1rem 1.25rem; margin: 1rem 0; }
              ul { margin: 0.5rem 0 0 1.25rem; }
              code { background: #f6f6f6; padding: 0.15rem 0.35rem; border-radius: 6px; }
              a { text-decoration: none; }
              a:hover { text-decoration: underline; }
            </style>
          </head>
          <body>
            <h1>Italo GTFS Export</h1>
            <p class="muted">
              Published from the repoâ€™s <code>gh-pages</code> branch. The workflow regenerates the GTFS and reports on schedule.
            </p>

            <div class="card">
              <h2>Downloads</h2>
              <ul>
                <li><a href="gtfs/italo_latest.zip">italo_latest.zip</a> (stable URL)</li>
                <li><a href="gtfs/latest.json">latest.json</a> (run metadata)</li>
              </ul>
            </div>

            <div class="card">
              <h2>Reports</h2>
              <ul>
                <li><a href="reports/">Open reports index</a></li>
                <li><a href="reports/missing_routes_latest.md">Missing routes (MD)</a></li>
                <li><a href="reports/stops_report_latest.md">Stops report (MD)</a></li>
              </ul>
            </div>

            <div class="card">
              <h2>How to update coordinates</h2>
              <ol>
                <li>Edit <code>coordinates.csv</code> locally</li>
                <li><code>git pull</code> / <code>git push</code></li>
                <li>Next run incorporates new lat/lon into <code>stops.txt</code></li>
              </ol>
            </div>
          </body>
          </html>
          EOF
      
      - name: Publish to GitHub Pages (gh-pages)
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          keep_files: true