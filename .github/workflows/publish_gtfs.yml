name: Build & Publish Italo GTFS + Stop Report

on:
  workflow_dispatch:
  schedule:
    - cron: "12 * * * *" # hourly (UTC)

permissions:
  contents: write

concurrency:
  group: italo-gtfs-publish
  cancel-in-progress: true

jobs:
  build_publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      - name: Compute vars
        id: vars
        run: |
          # Use tomorrow if you want day-after logic:
          # echo "SERVICE_DATE=$(date -u -d 'tomorrow' +%Y%m%d)" >> $GITHUB_OUTPUT
          echo "SERVICE_DATE=$(date -u +%Y%m%d)" >> $GITHUB_OUTPUT

      - name: Scrape (from trains.txt)
        run: |
          mkdir -p out

          python scraper/italo_scrape.py \
            --trains-file scraper/trains.txt \
            --outdir out \
            --slice-size 999999 \
            --slice-index 0 \
            --skip-empty

          RUN_UTC=$(ls -1 out | sort | tail -n 1)
          echo "RUN_UTC=$RUN_UTC" >> $GITHUB_ENV
          echo "Scrape run folder: out/$RUN_UTC"

      - name: Normalize
        run: |
          OUTDIR="out/$RUN_UTC"
          NORMDIR="normalized/$RUN_UTC"
          mkdir -p "$NORMDIR"

          python scraper/normalize_italo.py --input-dir "$OUTDIR" --output-dir "$NORMDIR"

      - name: Build GTFS (stable + dated)
        run: |
          SERVICE_DATE="${{ steps.vars.outputs.SERVICE_DATE }}"
          NORMDIR="normalized/$RUN_UTC"

          mkdir -p gtfs public/gtfs public/reports

          python scraper/build_gtfs.py \
            --normalized-dir "$NORMDIR" \
            --service-date "$SERVICE_DATE" \
            --out-zip "gtfs/italo_$SERVICE_DATE.zip"

          cp "gtfs/italo_$SERVICE_DATE.zip" "public/gtfs/italo_latest.zip"
          cp "gtfs/italo_$SERVICE_DATE.zip" "public/gtfs/italo_$SERVICE_DATE.zip"

          cat > public/gtfs/latest.json <<EOF
          {
            "run_utc": "$RUN_UTC",
            "service_date": "$SERVICE_DATE",
            "latest_zip": "italo_latest.zip",
            "dated_zip": "italo_$SERVICE_DATE.zip"
          }
          EOF

          if [ -f public/index.html ]; then
            echo "index.html already in public/"
          elif [ -f index.html ]; then
            cp index.html public/index.html
          else
            echo "No index.html found (expected public/index.html in repo)."
          fi

      - name: Stop coordinates report (read-only coordinates.csv)
        run: |
          python scraper/report_stops.py \
            --normalized-dir "normalized/$RUN_UTC" \
            --coordinates "coordinates.csv" \
            --out-dir "public/reports" \
            --run-utc "$RUN_UTC"

      - name: Publish to GitHub Pages (gh-pages)
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          keep_files: true